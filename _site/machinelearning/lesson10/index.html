<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.21.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Linear Regression - The Learning Journey</title>
<meta name="description" content="The goal of linear regression is to make a continuous value prediction for a given input after having trained the model on a labeled data set. Take for instance this simple problem of predicting the salary for an employee based on the number of years of experience.">


  <meta name="author" content="Vikram Meyer">
  
  <meta property="article:author" content="Vikram Meyer">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="The Learning Journey">
<meta property="og:title" content="Linear Regression">
<meta property="og:url" content="http://localhost:4000/machinelearning/lesson10/">


  <meta property="og:description" content="The goal of linear regression is to make a continuous value prediction for a given input after having trained the model on a labeled data set. Take for instance this simple problem of predicting the salary for an employee based on the number of years of experience.">







  <meta property="article:published_time" content="2020-12-16T22:56:36-05:00">





  

  


<link rel="canonical" href="http://localhost:4000/machinelearning/lesson10/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Vikram Meyer",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="The Learning Journey Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/profile.png" alt=""></a>
        
        <a class="site-title" href="/">
          The Learning Journey
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About Me</a>
            </li><li class="masthead__menu-item">
              <a href="/machinelearning/">Machine Learning</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">Artificial Intelligence</span>
        

        
        <ul>
          
            <li><a href="/machinelearning/lesson1/">What is Artificial Intelligence?</a></li>
          
            <li><a href="/machinelearning/lesson2/">Classifications of AI</a></li>
          
            <li><a href="/machinelearning/lesson3/">AI vs. ML vs. DL</a></li>
          
            <li><a href="/machinelearning/lesson4/">What is Machine Learning?</a></li>
          
            <li><a href="/machinelearning/lesson5/">3 Types of Machine Learning</a></li>
          
            <li><a href="/machinelearning/lesson6/">What is Deep Learning?</a></li>
          
            <li><a href="/machinelearning/lesson7/">ML vs. DL- Defining Features</a></li>
          
            <li><a href="/machinelearning/lesson8/">End Note</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Supervised Learning Algorithms</span>
        

        
        <ul>
          
            <li><a href="/machinelearning/lesson9/">Overview</a></li>
          
            <li><a href="/machinelearning/lesson10/" class="active">Linear Regression</a></li>
          
            <li><a href="/machinelearning/lesson11/">Logistic Regression</a></li>
          
            <li><a href="/machinelearning/lesson12/">Gradient Descent</a></li>
          
            <li><a href="/machinelearning/lesson13/">Gradient Descent Optimization Algorithms</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Neural Networks</span>
        

        
        <ul>
          
            <li><a href="/machinelearning/lesson14/">Overview</a></li>
          
            <li><a href="/machinelearning/lesson15/">Activation Functions</a></li>
          
            <li><a href="/machinelearning/lesson16/">Backpropagation</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Error Analysis</span>
        

        
        <ul>
          
            <li><a href="/machinelearning/lesson17/">Overview</a></li>
          
            <li><a href="/machinelearning/lesson18/">Overfitting vs. Underfitting Analogy</a></li>
          
            <li><a href="/machinelearning/lesson19/">Overfitting vs. Underfitting</a></li>
          
            <li><a href="/machinelearning/lesson20/">Solutions</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Linear Regression">
    <meta itemprop="description" content="The goal of linear regression is to make a continuous value prediction for a given input after having trained the model on a labeled data set. Take for instance this simple problem of predicting the salary for an employee based on the number of years of experience.">
    <meta itemprop="datePublished" content="2020-12-16T22:56:36-05:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Linear Regression
</h1>
          


        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>The goal of linear regression is to make a continuous value prediction for a given input after having trained the model on a labeled data set. Take for instance this simple problem of predicting the salary for an employee based on the number of years of experience.</p>

<p><img src="/assets/images/ML_images/SupervisedLearning/LinRegProblem.png" alt="Linear Regression Problem" /></p>

<p>In order to predict the salary for an employee $y$ for an input of years of experience $x$, we will construct a hypothesis that outputs a prediction for an input $x$: $h_\theta(x) = \theta_0 + \theta_1 x_1$. In this simple case of linear regression, the hypothesis is in the form of the equation of a line ($y = mx +b$) where the slope is $\theta_1$ and the y-intercept is $\theta_0$. Once the parameters $\theta_0$ and $\theta_1$ are optimized to the best value using the gradient descent algorithm that will be discussed later, the result is a line of best fit (pictured above) that can be used to make predictions for new inputs.</p>

<p>When implementing this linear regression, it is best to use matrices so we slightly modify the hypothesis by adding a new feature $x_0$ that is always equal to 1 and passing a matrix of features to the hypothesis. This additional feature helps the shapes of the parameter matrix and feature matrix align better for matrix multiplication so that the hypothesis can be represented by a concise statement of matrix multiplication as seen in equation \ref{linRegEqn} (Note the parameter matrix $\theta$ is transposed so that the matrix multiplication is (1 x 2) x (2 x 1) = (1 x 1).</p>

\[\begin{equation}
    h_\theta(X) = \theta_0x_0 + \theta_1x_1
\end{equation}\]

\[\begin{equation}
X=\left[\begin{array}{l}
x_{0} \\
x_{1}
\end{array}\right] \quad \theta=\left[\begin{array}{l}
\theta_{0} \\
\theta_{1}
\end{array}\right]
\end{equation}\]

\[\begin{equation} \label{linRegEqn}
    h_\theta(X) = \theta^TX
\end{equation}\]

<p>Next, in order to find the optimal values for $\theta_0$ and $\theta_1$ through gradient descent, we need to define a cost function that determines the error between the predicted output and actual output. A popular cost function for simple supervised learning tasks on continuous values is the \textbf{Mean Squared Error (MSE)} cost function. This cost function simply finds the difference between the predicted ($h(x)$) and actual ($y$) and then squares that difference (The $i$ superscript denotes the ith training example). The cost for one iteration is the average of the cost for all the training examples (as evident by the summation symbol). Note that $m$ is the number of training examples.</p>

\[\begin{equation}
    J(\theta_0,\theta_1) = \frac{1}{2m} \sum\limits_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2
\end{equation}\]

<p>With the cost function defined, we can use the gradient descent algorithm discussed later on to find the optimal values for $\theta_0$ and $\theta_1$ that produce the most accurate predictions and the lowest cost.</p>

<p>Below is the update rule for gradient descent for linear regression. It is important to note that the parameters should be updated simultaneously. This means that the derivative of the cost function with respect to $\theta_0$ and $\theta_1$ should be calculated first before updating both $\theta_0$ and $\theta_1$. This is important so that the update of one parameter does not effect the update of the other simply because of the order in which they were calculated.</p>

<p><img src="/assets/images/ML_images/SupervisedLearning/LinRegUpdateRule.png" alt="Linear Regression Update Rule" /></p>

<p>For those with a calculus background who are interested in what the actual derivatives are for linear regression’s MSE cost function, the equations are displayed below. While being able to derive the derivatives of the cost function is helpful in building an intuition for how gradient descent works, most all machine learning projects now have functions that automatically compute the numerous derivatives required for complex machine learning problems.</p>

\[\begin{array}{l}
\frac{\partial}{\partial \theta_{0}} J\left(\theta_{0}, \theta_{1}\right)=\frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \\
\frac{\partial}{\partial \theta_{1}} J\left(\theta_{0}, \theta_{1}\right)=\frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \cdot x^{(i)}
\end{array}\]

<h3 id="multivariate-linear-regression">Multivariate Linear Regression</h3>
<p>The previous example involved a problem with one feature. However, oftentimes relationships are more complex and involve multiple features to predict an output, this is where multivariate linear regression can be used.
The only difference between the previously discussed univariate linear regression and multivariate linear regression is that the latter makes predictions based on more features. For example, instead of predicting the salary of an employee based on years of experience, the salary might also depend on education level, college degree, area of residence.</p>

<p>Take the table below as an example, where the goal is to predict the numbers of units of product sold based on the advertising spent on TV, radio, and newspaper ads. In this example, there are 3 features (TV, radio, and newspaper spending) and there are 4 observations/training examples represented in the table. In reality, it would take many times more training examples to get an accurate model.</p>

<p><img src="/assets/images/ML_images/SupervisedLearning/multivariate.png" alt="Multivariate Linear Regression" /></p>

<p>We can use the table above to establish some notation that will be useful later. $x^{(i)}$ refers to the feature vector of the ith training example. In order to specify specific features, we use another index as a subscript $x^{(i)}_j$ to indicate the jth feature in the ith training example. For example, in the above table, $x^3_2$ refers to the 2nd feature of the training example at index 3 which is 41.9 (remember arrays/lists are 0 indexed). It is important to note that features and training examples are 0-indexed and the feature at $x_0$ always has a value of 1.</p>

<p>In the case of one feature the hypothesis can be visualized as a line in 2D space with two parameters. In the case of two features the hypothesis can be visualized as a plane in 3D space with three parameters. Any number of features above two becomes nearly impossible to visualize that is why it is important to build the intuition with basic examples and use your understanding of the mathematical notation to support your intuition in more complex problems.</p>

<p>Luckily, the use of matrix notation to setup the linear regression algorithm allows us to easily extend the problem from one feature to $n$ features such that the hypothesis may look like this: $h_\theta(x)=\theta_{0} x_{0}+\theta_{1} x_{1}+\ldots+\theta_{n} x_{n}$ but still is expressed as $h_\theta(x) = \theta^T x$ where $\theta$ and $x$ are vectors from $\theta_0$ to $\theta_n$ and $x_0$ to $x_n$ respectively. Thus, when implemented in code univariate and multivariate linear regression are the same and it is merely the data passed in as features that distinguishes between the two types.</p>

        
      </section>

      <footer class="page__meta">
        
        


        
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-12-16T22:56:36-05:00">December 16, 2020</time></p>


      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=Linear+Regression%20http%3A%2F%2Flocalhost%3A4000%2Fmachinelearning%2Flesson10%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fmachinelearning%2Flesson10%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fmachinelearning%2Flesson10%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/machinelearning/lesson9/" class="pagination--pager" title="Supervised Learning Algorithms Overview
">Previous</a>
    
    
      <a href="/machinelearning/lesson11/" class="pagination--pager" title="Logistic Regression
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://github.com/meyerv11045" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Vikram Meyer. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
